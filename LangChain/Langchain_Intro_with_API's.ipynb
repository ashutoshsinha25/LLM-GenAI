{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpiRegdeQClm3VDV9QsJHL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashutoshsinha25/LLM-GenAI/blob/main/LangChain/Langchain_Intro_with_API's.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain"
      ],
      "metadata": {
        "id": "mV2W6DhZHZoe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain"
      ],
      "metadata": {
        "id": "arfshLv5KHyK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "langchain.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Q03ekh_UKqEv",
        "outputId": "93a67fe0-6d20-48de-dc95-c1d98e97fed4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.2.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "import os"
      ],
      "metadata": {
        "id": "xNSE760DPqXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading keys in python\n",
        "# from dotenv import load_dotenv\n",
        "# _ = load_dotenv()"
      ],
      "metadata": {
        "id": "iPDPjiQpgTkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading keys in colab\n",
        "# from google.colab import userdata\n",
        "# userdata.get('secretName')"
      ],
      "metadata": {
        "id": "dXrUlkBWgV6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
        "HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACE_API_KEY\")"
      ],
      "metadata": {
        "id": "zHpgszGMgXlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the LLM models for our LLM application"
      ],
      "metadata": {
        "id": "X3mzB15ROOrH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HuggingFace with LangChain"
      ],
      "metadata": {
        "id": "mLeAic1WgiN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# huggingface model\n",
        "# from langchain import HuggingFaceHub (depricated)\n",
        "from langchain_community.llms import HuggingFaceHub"
      ],
      "metadata": {
        "id": "wfrdYIzNKsa4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = \"Tell me about Japan and its war history\""
      ],
      "metadata": {
        "id": "VtlSs9NOgoDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME =  \"google/gemma-7b\"\n",
        "gemma = HuggingFaceHub(repo_id = MODEL_NAME , huggingfacehub_api_token = HUGGINGFACE_API_KEY)"
      ],
      "metadata": {
        "id": "lDl3LsHIgoXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = gemma.predict(test)\n",
        "ques = val.split(\"\\n\\n\" , maxsplit= 1)[0]\n",
        "ans = val.split(\"\\n\\n\" , maxsplit= 1)[1]"
      ],
      "metadata": {
        "id": "Q_TYD969gpmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ques"
      ],
      "metadata": {
        "id": "g_7RXyQqgrQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ans.strip())"
      ],
      "metadata": {
        "id": "faJBBu3fgsKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "mistral = gemma = HuggingFaceHub(repo_id = MODEL_NAME , huggingfacehub_api_token = HUGGINGFACE_API_KEY)"
      ],
      "metadata": {
        "id": "t1xJgnFXgtw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = mistral.predict(test)\n",
        "ques = val.split(\"\\n\\n\" , maxsplit= 1)[0]\n",
        "ans = val.split(\"\\n\\n\" , maxsplit= 1)[1]"
      ],
      "metadata": {
        "id": "idyMRwulgur_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ques"
      ],
      "metadata": {
        "id": "EMbjBPmwgy_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ans.strip())"
      ],
      "metadata": {
        "id": "NcKfURZEgy6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenAI with LangChain"
      ],
      "metadata": {
        "id": "WBLhvtVtgbkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from langchain_community.llms import OpenAI # (prefered)\n",
        "# from langchain_openai import OpenAI # (prefered)\n",
        "# from langchain.llms import OpenAI (depricated)"
      ],
      "metadata": {
        "id": "Fx95G7FyN3XX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI()\n",
        "text = \"can you tell me about the India\"\n",
        "llm.predict(text)"
      ],
      "metadata": {
        "id": "sfhZNf59ge6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google(gemini) with LangChain"
      ],
      "metadata": {
        "id": "8drgKXrgg19-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# google model\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "4f12ZAt_N4-U"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'gemini-pro'\n",
        "gemini = ChatGoogleGenerativeAI(model=MODEL_NAME , google_api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "bCmZPwAhN6cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = gemini.invoke(test)"
      ],
      "metadata": {
        "id": "ygCDD3ewg7gG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(val.content)"
      ],
      "metadata": {
        "id": "WLRBM1Ixg9CN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}